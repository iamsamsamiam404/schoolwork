% Created 2024-06-22 Sat 23:07
% Intended LaTeX compiler: pdflatex
\documentclass[letterpaper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage[margin=1in]{geometry}
\usepackage{float}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{Interprise Virtualization}
\rfoot{\thepage} % Right footer with page number
\setcounter{tocdepth}{2}
\date{\today}
\title{}
\hypersetup{
 pdfauthor={},
 pdftitle={},
 pdfkeywords={},
 pdfsubject={Lab report 2 for CNIT 242},
 pdfcreator={Emacs 29.3 (Org mode 9.6.24)}, 
 pdflang={English}}
\begin{document}

\tableofcontents

\newpage
\setcounter{tocdepth}{2}
\tableofcontents

\section{Executive Summary}
\label{sec:orgc89c46d}
This lab report details the project undertaken by Yorkshire, a growing school system, to enhance its IT infrastructure by transitioning to a fully virtualized environment using VMware vSphere. The primary objectives were to optimize resource utilization, improve scalability, and strengthen disaster recovery capabilities. The project involved replacing Yorkshire's existing combination of physical and virtual servers with a more efficient and scalable virtual solution. Key technologies used included VMware vSphere, VMware ESXi, vCenter Server, VMware Workstation, VMware Converter, Windows Server 2019, Windows 10, Windows Server 2022, Active Directory, and an iSCSI SAN LUN formatted as a VMFS datastore.

The lab was executed in two main phases. Phase I focused on setting up the environment, which involved installing and configuring two ESXi servers, deploying the vCenter Server Virtual Appliance, and migrating existing virtual machines (VMs) from a VMware Workstation environment into the new ESXi environment. Phase II concentrated on configuring the SAN datastore and managing virtual machines, including tasks like integrating Active Directory, configuring network adapters, and setting up a VMFS datastore on the SAN.

Several significant accomplishments were achieved during this project. Two ESXi servers were successfully installed and configured with appropriate hardware settings. The vCenter Server was deployed and integrated into the Active Directory domain, facilitating better management and security. The Windows 11 VM was successfully migrated from VMware Workstation to the ESXi server. Additionally, the physical-to-virtual (P-to-V) conversion of the domain controller was completed using VMware Converter. The SAN datastore was configured to be accessed by both ESXi servers, providing a shared storage solution. A new Windows Server 2019 VM was installed and saved as a template for future use. VMware snapshots and vMotion were utilized to manage and migrate VMs effectively.

Despite these successes, the project encountered some challenges. One major issue was the initial failure to join the vCenter Server to the Active Directory domain due to DNS resolution problems. This was resolved by manually specifying the domain controller's IP address during the domain join process. Another issue was the failure of the P-to-V conversion due to insufficient disk space on the target ESXi server, which was resolved by correctly configuring the thin provisioned disk size.

In conclusion, the project successfully achieved its goals of fully virtualizing and optimizing Yorkshire's IT infrastructure. The recommendations for future improvements include regularly taking snapshots before making significant changes, ensuring proper disk provisioning settings, verifying DNS and network settings before joining domains, and regularly rescanning storage adapters when configuring shared storage.

The appendices of this report contain detailed problem-solving documentation for the issues encountered, including the steps taken to resolve them, ensuring a comprehensive understanding of the project's challenges and solutions.
\section{Business Case}
\label{sec:org42ff23a}
Yorkshire is a small but rapidly expanding school system driven by rising suburbanization and increasing demand for its IT services. To meet these growing demands, Yorkshire embarked on a project to enhance its IT infrastructure by transitioning to a fully virtualized environment. This project aimed to optimize resource utilization, improve scalability, and strengthen disaster recovery capabilities. The primary objective was to replace Yorkshire's current combination of physical and virtual servers with a more efficient and scalable solution using VMware vSphere. The specific goals included improving the utilization of IT resources to handle the increasing workload efficiently, ensuring the infrastructure could easily scale to accommodate future growth, and enhancing disaster recovery capabilities to minimize downtime and data loss in case of hardware failures or other disruptions.The applications and technologies used in this project included VMware vSphere, VMware ESXi, vCenter Server, VMware Workstation, VMware Converter, Windows Server 2019, Windows 10, Windows Server 2022, Active Directory, and an iSCSI SAN LUN formatted as a VMFS datastore. By transitioning to a fully virtualized environment, Yorkshire aimed to provide a more reliable, scalable, and efficient IT infrastructure, better suited to support its growing needs and future expansion plans.
\section{Procedures}
\label{sec:org511b1e8}

In this lab, we followed a two-phase process to convert a virtual environment into a nested virtual environment using VMware vSphere. Each phase had distinct objectives and steps, which were organized based on tasks and components involved. This documentation is written in past tense to accurately describe the procedures followed. The formatting is as follows: buttons are \textbf{bold}, options are \uline{italicized}, text entered into the computer is in `code`, and menu navigation is indicated by the pipe symbol and italic words: \uline{Start | Programs | MS Office | Word}.

\subsection{Phase I: Setting Up the Environment}
\label{sec:org8744173}
\subsubsection{1. Install ESXi Servers:}
\label{sec:org7399bb3}
\begin{itemize}
\item Configured hardware settings: set CPU, hard disk, memory, and port group.
\begin{itemize}
\item \uline{CPU}: 8 CPUs
\item \uline{Memory}: 32 GB RAM
\item \uline{Hard Disk}: 1 TB Thin Provisioned Disk
\item \uline{Enable hardware virtualization}: Check \textbf{Expose hardware-assisted virtualization to the guest OS} under the \uline{CPU} tab.
\end{itemize}
\item Launched the ESXi server installer:
\begin{itemize}
\item Inserted the ESXi installer ISO and booted the server.
\item Accepted the default options to complete the installation.
\end{itemize}
\item Connected to the ESXi server via a Windows 10 machine:
\begin{itemize}
\item Opened a browser and navigated to the ESXi server's IP address.
\item Logged in with the credentials created during installation.
\end{itemize}
\end{itemize}

\subsubsection{2. Install vCenter Server Virtual Appliance:}
\label{sec:orgf87d1b9}
\begin{itemize}
\item Accessed the RTFM fileshare and opened the installer:
\begin{itemize}
\item Navigated to the folder containing the installer: \uline{win32 installer}.
\item Launched the installer.
\end{itemize}
\item Followed the installation steps:
\begin{itemize}
\item Entered the ESXi IPv4 settings, username, and password.
\item Set up the root password and name.
\item Configured the deployment size (left as default).
\item Enabled thin disk mode.
\item Assigned an IP address, set the default gateway and network mask.
\item Entered the DNS server IP from the Windows server.
\item Verified settings and clicked \textbf{Finish}.
\item Waited for the installation to complete.
\end{itemize}
\end{itemize}

\subsubsection{3. Configuration and Deployment:}
\label{sec:org68890c1}
\begin{itemize}
\item Completed Phase I and proceeded to Phase II by clicking \textbf{Next}.
\item Added the ESXi host:
\begin{itemize}
\item Opened vCenter and logged in with `administrator@vsphere.local`.
\item Navigated to \uline{Hosts and Clusters}.
\item Clicked \textbf{Add Host}.
\item Entered the ESXi host IP address, username, and password.
\item Accepted the default options to complete the addition of the host.
\end{itemize}
\item Activated SSH:
\begin{itemize}
\item Selected the ESXi host and navigated to \uline{Configure | Services}.
\item Located \textbf{SSH}, clicked \textbf{Edit}, and set it to \textbf{Start and stop with host}.
\end{itemize}
\item Created a new Single Sign-On (SSO) domain:
\begin{itemize}
\item During vCenter setup, created an SSO domain named `vsphere.local`.
\item Set up the SSO password, clicked \textbf{Next}, and finished the setup.
\item Closed the setup wizard.
\end{itemize}
\end{itemize}

\subsubsection{4. vSphere Setup:}
\label{sec:org85f3c56}
\begin{itemize}
\item Logged into vSphere using `administrator@vsphere.local`.
\item Created a new datacenter:
\begin{itemize}
\item Navigated to \uline{Hosts and Clusters}.
\item Right-clicked on the vCenter server and selected \textbf{New Datacenter}.
\item Named the datacenter and clicked \textbf{OK}.
\end{itemize}
\item Added ESXi hosts:
\begin{itemize}
\item Right-clicked the newly created datacenter and selected \textbf{Add Host}.
\item Entered the IP address, username, and password of the ESXi host.
\item Accepted the default prompts to add the host to the datacenter.
\end{itemize}
\item Configured the ESXi management network:
\begin{itemize}
\item Pressed `F2` on the ESXi host console to customize the system.
\item Navigated to \uline{Configure Management Network | IPv4 Configuration}.
\item Set static IPv4 address, subnet mask, and default gateway.
\item Navigated to \uline{DNS Configuration} and set the DNS server to the Windows server IP.
\item Restarted the management network.
\end{itemize}
\end{itemize}

\subsubsection{5. Active Directory Integration:}
\label{sec:orgddb2d50}
\begin{itemize}
\item Configured NTP, hostname, DNS, and gateway for vCenter:
\begin{itemize}
\item Logged into vSphere.
\item Navigated to \uline{Administration | System Configuration}.
\item Selected the vCenter server and clicked \textbf{Configure}.
\item Set NTP settings, hostname, DNS, and gateway.
\end{itemize}
\item Joined Active Directory Domain:
\begin{itemize}
\item Navigated to \uline{Administration | Active Directory Domain}.
\item Clicked \textbf{Join Domain}, entered the domain details, and rebooted the node.
\end{itemize}
\item Configured forward zone for vCenter in the DNS server.
\end{itemize}

\subsubsection{6. Moving Windows 11 Virtual Machine:}
\label{sec:org3dae654}
\begin{itemize}
\item Used VMware Converter to move the VM from Windows 11 Workstation to ESXi server:
\begin{itemize}
\item Opened VMware Converter.
\item Selected \textbf{Convert Machine}.
\item Chose the option for VMware Workstation or other VMware virtual machine.
\item Browsed and selected the virtual machine file.
\item Entered vCenter IP and SSO information.
\item Verified settings and clicked \textbf{Finish}.
\end{itemize}
\end{itemize}

\subsubsection{7. Physical to Virtual (P-to-V) Conversion:}
\label{sec:org4b09724}
\begin{itemize}
\item Installed VMware Converter on the domain controller:
\begin{itemize}
\item Downloaded and installed VMware Converter.
\item Launched the Converter and selected the domain controller as the source.
\item Set the destination as vCenter using its IP and SSO credentials.
\item Chose thin provisioning and accepted defaults.
\item Shut down the original server.
\item Powered on the new virtual server in vCenter.
\item Reconfigured IPv4 settings to the previous settings for the domain controller.
\end{itemize}
\end{itemize}
\subsection{Phase II: Configuring SAN Datastore and Managing Virtual Machines}
\label{sec:orgb361e03}
\subsubsection{1. Configure SAN Datastore:}
\label{sec:org40221ef}
\begin{itemize}
\item Logged into vCenter.
\item Clicked on the ESXi host, navigated to \uline{Configure | Storage Adapters}.
\item Added a new iSCSI adapter:
\begin{itemize}
\item Clicked \textbf{Add Software Adapter}.
\item Selected the iSCSI adapter created.
\item Went to \uline{Dynamic Discovery} and added the SAN IP address.
\end{itemize}
\end{itemize}

\subsubsection{2. Network Adapter Configuration:}
\label{sec:org18f89cd}
\begin{itemize}
\item Opened vCenter, selected the ESXi server.
\item Under VM Hardware, added a new network adapter:
\begin{itemize}
\item Clicked \textbf{Edit} under the VM Hardware section.
\item Selected \textbf{Add New Device} and chose \textbf{Network Adapter}.
\item Configured the new network adapter to use the CNIT242 iSCSI port group.
\item Clicked \textbf{OK}.
\end{itemize}
\end{itemize}

\subsubsection{3. Storage Configuration:}
\label{sec:orgb122818}
\begin{itemize}
\item Repeated the above steps for the second ESXi host.
\item Created a new VMFS datastore:
\begin{itemize}
\item Clicked \textbf{Storage}.
\item Selected \textbf{New Datastore}.
\item Chose \textbf{VMFS} and selected the FreeNAS iSCSI disk.
\item Used the full disk and selected VMFS 6.
\end{itemize}
\item Added VM Kernel NIC:
\begin{itemize}
\item Navigated to \uline{Networking}.
\item Clicked \textbf{Add VMkernel NIC}.
\item Created a new port group named CNIT242 iSCSI.
\item Selected the appropriate vSwitch and set IPv4 to static.
\item Entered IP address `192.168.52.10` and subnet mask `255.255.255.0`.
\item Clicked \textbf{Create}.
\end{itemize}
\end{itemize}

\subsubsection{4. Enable iSCSI Adapter:}
\label{sec:orgbd80a8a}
\begin{itemize}
\item Navigated to \uline{Storage}.
\item Selected the iSCSI adapter and ensured it was enabled.
\item Added dynamic targets:
\begin{itemize}
\item Clicked \textbf{Port Bindings} and selected the VMkernel interface created.
\item Added a dynamic target with IP address `192.168.52.254` and port `3260`.
\end{itemize}
\end{itemize}

\subsubsection{5. Installed Windows Server 2019 Virtual Machine:}
\label{sec:org6daeb62}
\begin{itemize}
\item Inside vCenter, navigated to the target datastore (e.g., datastore1).
\item Clicked \textbf{Upload Files}.
\item Accessed the network location `$\backslash$\rtfm.cit.lcl`.
\item Located and selected the Windows Server 2019 ISO file.
\item Selected an ESXi host (e.g., 44.100.10.191).
\item Created a new virtual machine:
\begin{itemize}
\item Named it WindowsServer2019.
\item Selected datastore and compute resource (ESXi host address).
\item Chose storage (same datastore as before).
\item Compatibility set to ESXi 8 and later.
\item Accepted defaults for guest OS.
\item Modified disk provisioning to \textbf{Thin}.
\item Added CD/DVD drive, connected ISO file (`datastore1` → Windows Server 2019 ISO).
\item Finished setup.
\end{itemize}
\item Powered on Windows Server 2019 VM.
\item Proceeded with installation, created admin account.
\item Installed VMware Tools, mounted and ran setup.
\item Configured network settings (Ethernet0):
\begin{itemize}
\item Set IP address to 44.100.10.11, subnet mask to 255.255.255.0, default gateway to 44.100.10.1, DNS to 44.100.10.10.
\end{itemize}
\item Restarted Windows Server 2019.
\item Checked for updates, installed, and restarted.
\item Configured NTP time server:
\begin{itemize}
\item Opened Command Prompt as admin.
\item Configured time server: `w32tm /config /manualpeerlist:``tick.cit.lcl'' /syncfromflags:manual /reliable:YES /update`.
\item Resynchronized time: `w32tm /resync`.
\item Verified changes: `w32tm /query /status`.
\end{itemize}
\item Powered off Windows Server 2019.
\item Converted VM to template: Right-clicked → \textbf{Template} → \textbf{Convert to template}.
\item Moved template to SAN datastore:
\begin{itemize}
\item Navigated to ESXi host interface holding Windows Server 2019.
\item Went to \textbf{Storage} → \textbf{Datastore Browser}.
\item Located template on `datastore1`, moved it to `SANdatastoreG10`.
\end{itemize}
\item Registered template as VM in vCenter:
\begin{itemize}
\item Navigated to the folder where Windows Server 2019 template was moved (SANdatastoreG10).
\item Found `.vmtx` file, clicked to select.
\item Clicked \textbf{Register VM}.
\item Named VM, selected datastore, compute resource, and finished.
\end{itemize}
\end{itemize}

\subsubsection{6. Set Permissions:}
\label{sec:orga63cf1a}
\begin{itemize}
\item Inside vCenter, navigated to Windows 11 VM.
\item Went to \textbf{Permissions} tab.
\item Clicked \textbf{Add}.
\item Changed domain to Active Directory domain (`group10.c242.cit.lcl`).
\item Added user (e.g., ESstudents).
\item Assigned role (e.g., Read only).
\item Clicked \textbf{OK}.
\end{itemize}

\subsubsection{7. Migrated Storage to SAN (Storage vMotion):}
\label{sec:org3aa8303}
\begin{itemize}
\item Inside vCenter, found Windows 11 VM in the sidebar.
\item Right-clicked and selected \textbf{Migrate}.
\item Chose \textbf{Change storage only}.
\item Clicked \textbf{Next}.
\item In \textbf{Select Storage}, chose:
\begin{itemize}
\item Virtual disk format: \textbf{Thin Provision}.
\item Destination datastore: `SANdatastoreG10`.
\end{itemize}
\item Clicked \textbf{Next} and \textbf{Finish}.
\item Monitored progress in \textbf{Monitor → Tasks and Events → Tasks}.
\item VM could still be used during migration.
\end{itemize}

\subsubsection{8. Migrated Compute Resource (vMotion):}
\label{sec:org937775c}
\begin{itemize}
\item Inside vCenter, found Windows 11 VM in the sidebar.
\item Right-clicked and selected \textbf{Migrate}.
\item Chose \textbf{Change compute resource only}.
\item Clicked \textbf{Next}.
\item Selected the target ESXi host (e.g., `44.100.10.192`).
\item Accepted default options.
\item Clicked \textbf{Finish}.
\item VM remained operational during migration.
\end{itemize}
\newpage
\section{Results}
\label{sec:orga8e78d3}
In this lab, a nested virtual environment was successfully created and configured using VMware vSphere. This involved setting up two ESXi servers, installing a vCenter server, and migrating existing virtual machines from a VMware Workstation environment into the new ESXi environment. Various VMware tools and techniques were utilized to manage and optimize the virtual environment, ensuring efficient resource allocation and network configuration. The following sections detail the physical and logical network setups, the IP schema, and computer names along with login information.
\subsection{Summary of Accomplishments}
\label{sec:org00456ef}
\begin{itemize}
\item Installation and Configuration of ESXi Servers
\begin{itemize}
\item Two ESXi servers were successfully installed and configured with 8 CPUs, 32 GB RAM, and 1 TB thin provisioned disks. Hardware virtualization was enabled.
\end{itemize}
\end{itemize}
\begin{figure}[H]
\centering
\includegraphics[width=14cm]{/home/sam/Screenshots/screenshot_2024-06-20_16-18-56.png}
\caption{Outer vCenter virtualization environment. Specifically showing information on ESXi1.2}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=14cm]{/home/sam/Screenshots/screenshot_2024-06-20_16-25-20.png}
\caption{Inside ESXi2.1's web interface. Shows the VMkernal NIC's inside the networking tab.}
\end{figure}
\begin{itemize}
\item Deployment of vCenter Server
\begin{itemize}
\item vCenter Server was installed, configured, and joined to the Active Directory domain.
\end{itemize}
\end{itemize}
\begin{figure}[H]
\centering
\includegraphics[width=14cm]{/home/sam/Screenshots/screenshot_2024-06-20_16-21-27.png}
\caption{Inner Vcenter virtualization environment. Specifically showing information on SCDC01.}
\end{figure}
\begin{itemize}
\item Migration of Windows 11 VM
\begin{itemize}
\item The Windows 11 VM was successfully migrated from VMware Workstation to the ESXi server and added to the inventory.
\end{itemize}
\end{itemize}
\begin{figure}[H]
\centering
\includegraphics[width=14cm]{/home/sam/Screenshots/screenshot_2024-06-20_16-26-27.png}
\caption{Inner vCenter virtualization environment. Shows the permissions for the windows 11 VM.}
\end{figure}
\begin{itemize}
\item P-to-V Conversion of Domain Controller
\begin{itemize}
\item Using VMware Converter, the domain controller was migrated from a physical to a virtual environment on the ESXi server.
\end{itemize}
\item Configuration of SAN Datastore
\end{itemize}
\begin{figure}[H]
\centering
\includegraphics[width=14cm]{/home/sam/Screenshots/screenshot_2024-06-20_16-23-08.png}
\caption{Inside ESXi2.1's web interface. Showing the datastores datastore1(1) and SANdatastoreG10.}
\end{figure}
\begin{itemize}
\item Both ESXi servers were configured to access an iSCSI SAN LUN and formatted as a VMFS datastore.
\end{itemize}
\begin{itemize}
\item Installation and Template Creation of Windows Server 2019
\begin{itemize}
\item A fresh Windows Server 2019 was installed, updated, and saved as a template for future use.
\end{itemize}
\item Virtual Machine Management
\begin{itemize}
\item VMware Snapshots were used to protect configurations during changes, and virtual machine access was controlled through vCenter permissions.
\end{itemize}
\item Virtual Machine Migration
\begin{itemize}
\item VMs were migrated between datastores and ESXi hosts using vMotion and storage vMotion.
\end{itemize}
\end{itemize}
\newgeometry{left=1cm,right=1cm,top=4cm,bottom=1cm}
\subsection{Machine Networking/Login Information Table}
\label{sec:org41e649c}
\centering
\begin{center}
\begin{tabular}{lrrl}
\hline
table & \textbf{ESXi1.2 Server} & \textbf{ESXi2.1 Server} & \textbf{vCenter}\\[0pt]
\hline
\textbf{Pnic1 (CNIT242G10A)} & 44.100.10.191 & 44.100.10.192 & 44.100.10.170\\[0pt]
\textbf{Pnic2 (CNIT242iSCSI)} & 192.168.52.10 & 192.168.54.10 & N/A\\[0pt]
\textbf{Subnet Mask} & 255.255.255.0 & 255.255.255.0 & 255.255.255.0\\[0pt]
\textbf{Default Gateway} & 44.100.10.1 & 44.100.10.1 & 44.100.10.1\\[0pt]
\textbf{DNS} & 44.100.10.10 & 44.100.10.10 & 44.100.10.10\\[0pt]
\textbf{SAN server IP} & 192.168.52.254 & 192.168.54.254 & N/A\\[0pt]
\textbf{Login} & root & root & administrator\\[0pt]
\textbf{Password} & Cnit242! & Cnit242! & Cnit242!\\[0pt]
\hline
\hline
 &  &  & \\[0pt]
table cont. & \textbf{Windows 2022 Srv.(SCDC01)} & \textbf{Windows 2019 Srv.} & \textbf{Windows 11 VM}\\[0pt]
\hline
\textbf{Pnic1 (CNIT242G10A)} & 44.100.10.10 & 44.100.10.11 & 44.100.10.111\\[0pt]
\textbf{Pnic2 (CNIT242iSCSI)} & N/A & N/A & N/A\\[0pt]
\textbf{Subnet Mask} & 255.255.255.0 & 255.255.255.0 & 255.255.255.0\\[0pt]
\textbf{Default Gateway} & 44.100.10.1 & 44.100.10.1 & 44.100.10.1\\[0pt]
\textbf{DNS} & 44.100.10.10 & 44.100.10.10 & 44.100.10.10\\[0pt]
\textbf{SAN server IP} & N/A & N/A & N/A\\[0pt]
\textbf{Login} & Administrator & Administrator & Administrator\\[0pt]
\textbf{Password} & Cnit242! & Cnit242! & Cnit242!\\[0pt]
\hline
\end{tabular}
\end{center}
\restoregeometry
\subsection{Diagrams}
\label{sec:org281fb02}
\begin{figure}[H]
\centering
\includegraphics[width=15cm]{/home/sam/Screenshots/screenshot_2024-06-22_21-54-02.png}
\caption{Physical topology diagram.}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=15cm]{/home/sam/Screenshots/screenshot_2024-06-22_21-56-42.png}
\caption{Logical topology diagram.}
\end{figure}
\section{Conclusions}
\label{sec:org0b23e38}
In the final analysis of the project, it can be concluded that it was a success in achieving the goal of fully virtualizing and optimizing the infrastructure at Yorkshire's school system. The primary objectives included installing and integrating two ESXi servers and configuring a SAN datastore, both of which were met effectively.

Firstly, the ESXi servers were successfully installed and configured. Using vCenter, these servers were joined to the pre-existing Active Directory domain, enabling administrators to assign VMs to users based on their group memberships. This integration was crucial for maintaining a seamless and secure IT environment.

Next, the migration of existing virtual machines was completed as planned. VMware Workstation facilitated the transfer of a Windows 11 VM to the ESXi server, while VMware Converter was utilized to perform a P-to-V conversion of the Windows Server 2022 domain controller, ensuring a smooth transition to the virtual environment.

The SAN datastore was then configured to access an iSCSI SAN LUN, formatted as a VMFS datastore. A new Windows Server 2019 VM was installed and saved as a template for future use. Subsequently, the Windows 11 VM was migrated from its local datastore on the ESXi server to the SAN datastore using storage vMotion. This configuration allowed administrators to move VMs freely between the two ESXi servers, enhancing resource flexibility and disaster recovery capabilities.

A snapshot was created to ensure there was a saved instance of the completed project, providing a reliable fallback option if needed. By successfully completing the objectives of installing and integrating ESXi servers, configuring the SAN datastore, and migrating VMs, the project achieved its overall goal of fully virtualizing and optimizing the school system’s infrastructure. Thus, the project can be deemed a success, meeting all requirements and expectations outlined in the business case.
\section{Recommendations}
\label{sec:orgd8d1751}
\subsection{Recommendation 1: Take Regular Snapshots}
\label{sec:org3228c4f}
Regularly take snapshots of your VMs, especially before making significant changes or updates. This allows you to quickly revert to a known good state if something goes wrong, saving time and effort in troubleshooting and recovery.

\subsection{Recommendation 2: Ensure Proper Disk Provisioning}
\label{sec:org36d5075}
When setting up the ESXi servers, double-check the disk provisioning settings to confirm that the thin provisioned disks are correctly configured to the intended size. Misconfigurations in disk size can lead to insufficient disk space issues, which can disrupt tasks such as P-to-V conversions.

\subsection{Recommendation 3: Verify DNS and Network Settings Before Joining Domains}
\label{sec:orgb89b6b1}
Before attempting to join the vCenter Server to the Active Directory domain, thoroughly verify DNS and network settings. Correct DNS configuration and network connectivity are crucial for successful domain integration. Manually specifying the domain controller's IP address can also help bypass potential DNS resolution issues.

\subsection{Recommendation 4: Regularly Rescan Storage Adapters When Configuring SAN}
\label{sec:orgca84894}
When configuring shared storage on ESXi servers, regularly rescan storage adapters to detect new devices and LUNs. This practice helps ensure that all storage resources are properly recognized and available for use. Additionally, verify iSCSI target configurations and LUN masking settings to avoid detection issues.

\section{Bibliography}
\label{sec:org6de7684}
Microsoft. (2022, August 16). Active Directory Domain Services Overview. Learn.microsoft.com. \url{https://learn.microsoft.com/en-us/windows-server/identity/ad-ds/get-started/virtual-dc/active-directory-domain-services-overview}

Microsoft. (2024a). Windows 11 overview for administrators - What’s new in Windows. Learn.microsoft.com.
\url{https://learn.microsoft.com/en-us/windows/whats-new/windows-11-overview}

Microsoft. (2024b). Windows Server Management documentation. Learn.microsoft.com.
\url{https://learn.microsoft.com/en-us/windows-server/administration/manage-windows-server}

VMware. (2019). VMware vSphere Documentation. Vmware.com.\\[0pt]
\url{https://docs.vmware.com/en/VMware-vSphere/index.html}

Rawles, P. (2024). Lab Instructor. Instruction Video.\\[0pt]
\url{https://purdue.brightspace.com} \\[0pt]

Wong, O. (2024). Lab TA. Personal communication.\\[0pt]
\url{https://discord.com}

Akpeokhai, O. (2024). Lab TA. Personal communication. \\[0pt]
\url{https://discord.com}

\section{APPENDIX: PROBLEM SOLVING}
\label{sec:org10e0614}

This section describes several issues faced throughout this project. Each problem is broken down by giving a Problem Description; listing Possible Solutions, accompanied by the reasoning for it; Solutions Attempted, which simply list which options from the Possible Solutions list that were attempted; and finally, a detailed description of the Final Solution and why it solved the problem.

\subsection{Problem 1: vCenter Server Fails to Join Active Directory Domain}
\label{sec:org010b1ab}
\subsubsection{Problem Description}
\label{sec:orgd95c3dc}
While attempting to join the vCenter Server Virtual Appliance to the Active Directory domain, the operation fails with an error indicating that the domain cannot be found. This issue occurs despite verifying that the network settings and DNS configurations appear correct. This problem prevents the vCenter Server from integrating with the AD domain, which is necessary for managing permissions and integrating with existing infrastructure.

\subsubsection{Possible Solutions}
\label{sec:orgfe52b3b}
\begin{itemize}
\item Check DNS Configuration: Ensure that the DNS server settings on the vCenter Server are correctly pointing to the domain controller's IP address. Incorrect DNS settings can prevent domain resolution.
\item Verify Network Connectivity: Test the network connectivity between the vCenter Server and the domain controller to ensure there are no network issues blocking the communication.
\item Update vCenter Server: Apply the latest updates and patches to the vCenter Server Virtual Appliance, as there may be known bugs or issues that have been fixed.
\item Manually Add Domain Controller: Manually specify the domain controller's IP address during the domain join process to bypass potential DNS resolution issues.
\item Check AD Credentials: Ensure that the credentials used for joining the domain have sufficient permissions and that there are no account restrictions.
\end{itemize}

\subsubsection{Solutions Attempted}
\label{sec:org5384434}
\begin{itemize}
\item Checked DNS Configuration.
\item Verified Network Connectivity.
\item Updated vCenter Server.
\end{itemize}

\subsubsection{Final Solution}
\label{sec:org950f6df}
The problem was resolved by manually specifying the domain controller's IP address during the domain join process. This bypassed the DNS resolution issue, allowing the vCenter Server to successfully join the Active Directory domain. Additionally, ensuring that the AD credentials used had sufficient permissions helped complete the operation without errors.

\subsection{Problem 2: P-to-V Conversion Fails Due to Insufficient Disk Space}
\label{sec:org1973f85}
\subsubsection{Problem Description}
\label{sec:orgd6c11df}
While performing a physical-to-virtual (P-to-V) conversion of the existing domain controller using VMware Converter, the process fails with an error indicating insufficient disk space on the target ESXi server. This issue occurs despite the intention to provision a 1 TB thin provisioned disk on the ESXi server. Upon further inspection, it was found that the disk size was improperly set up, and the actual allocated space was significantly less than 1 TB.

\subsubsection{Possible Solutions}
\label{sec:orgd934a49}
\begin{itemize}
\item Check Disk Space Allocation: Verify the actual disk usage on the ESXi server and ensure that there is enough physical storage available for the conversion process.
\item Increase Thin Provisioned Disk Size: Correct the thin provisioned disk size on the ESXi server to ensure it is properly set to 1 TB.
\item Clear Unnecessary Files: Remove unnecessary files and unused VMs from the ESXi server to free up disk space.
\item Use External Storage: Use an external storage device or an additional datastore to provide more disk space for the conversion.
\item Compress Source Disk: Compress the source disk of the physical machine before performing the conversion to reduce the amount of disk space needed.
\end{itemize}

\subsubsection{Solutions Attempted}
\label{sec:orgb2c6b42}
\begin{itemize}
\item Checked Disk Space Allocation.
\item Increased Thin Provisioned Disk Size.
\end{itemize}

\subsubsection{Final Solution}
\label{sec:orgfa6f3cd}
The problem was resolved by correcting the thin provisioned disk size on the ESXi server. It was discovered that the disk size was improperly configured, and the actual allocated space was much less than the intended 1 TB. By properly setting the thin provisioned disk to 1 TB, the ESXi server then had sufficient disk space for the P-to-V conversion process. After this adjustment, the conversion of the domain controller completed successfully. This solution was effective because it directly addressed the root cause of the disk space insufficiency without the need for additional hardware or extensive cleanup efforts.

\subsection{Problem 3: iSCSI SAN LUN Not Detected by ESXi Servers}
\label{sec:org20eab49}
\subsubsection{Problem Description}
\label{sec:orgefe9d53}
While attempting to configure both VMware ESXi servers to access an iSCSI SAN LUN and format it as a VMFS datastore, the LUN is not detected by the ESXi servers. This issue occurs despite confirming that the network settings for the iSCSI initiator and target are correct. The failure to detect the LUN prevents the configuration of shared storage necessary for advanced features like vMotion and high availability.

\subsubsection{Possible Solutions}
\label{sec:org06c5105}
\begin{itemize}
\item Verify iSCSI Target Configuration: Ensure that the iSCSI target is correctly configured to accept connections from the ESXi servers' IP addresses.
\item Check Network Connectivity: Confirm that there is proper network connectivity between the ESXi servers and the iSCSI SAN, including verifying that firewalls are not blocking iSCSI traffic.
\item Rescan Storage Adapters: Use the vSphere Client to rescan the storage adapters on the ESXi servers to detect new devices and LUNs.
\item Update ESXi Servers: Apply the latest updates and patches to the ESXi servers to address any known issues with iSCSI connectivity.
\item Verify iSCSI Initiator Configuration: Ensure that the iSCSI initiator on each ESXi server is correctly configured with the appropriate settings, such as the target portal IP address.
\end{itemize}

\subsubsection{Solutions Attempted}
\label{sec:orgc5fb7d3}
\begin{itemize}
\item Verified iSCSI Target Configuration.
\item Checked Network Connectivity.
\item Rescanned Storage Adapters.
\end{itemize}

\subsubsection{Final Solution}
\label{sec:org404a509}
The problem was resolved by adjusting the iSCSI target configuration on the SAN. It was discovered that the LUN masking settings on the iSCSI SAN were incorrectly configured, preventing the LUN from being visible to the ESXi servers. By correcting the LUN masking settings to explicitly allow access from the ESXi servers' initiator IQNs, the LUN was successfully detected. A rescan of the storage adapters in the vSphere Client then revealed the LUN, which was subsequently formatted as a VMFS datastore. This allowed the ESXi servers to access the shared storage as intended.
\end{document}

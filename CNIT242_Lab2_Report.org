#+title: Lab Report 2(Formatting still work in progress)
#+AUTHOR: Group 10
#+DATE:<2024-06-22 Sat>:
#+DESCRIPTION: Lab report 2 for CNIT 242
#+COMMENT: DUE:<2024-06-22 Sat>

#+TODO: TODO IN-PROGRESS WAITING | DONE CANCELED
#+OPTIONS: p:t todo:t

#+LATEX_CLASS_OPTIONS: [letterpaper,12pt]
#+LATEX_HEADER: \usepackage[margin=1in]{geometry}
#+LATEX_HEADER: \usepackage{float}

#+LaTeX_HEADER: \usepackage{fancyhdr}
#+LaTeX_HEADER: \pagestyle{fancy}
#+LaTeX_HEADER: \fancyhf{}
#+LaTeX_HEADER: \lhead{Lab Report 2 CNIT 242}

#+LATEX_HEADER: \setcounter{tocdepth}{2} % set table of contents to page 2
#+LATEX: \newpage
#+TOC: headlines 2

* Executive Summary
This lab report details the project undertaken by Yorkshire, a growing school system, to enhance its IT infrastructure by transitioning to a fully virtualized environment using VMware vSphere. The primary objectives were to optimize resource utilization, improve scalability, and strengthen disaster recovery capabilities. The project involved replacing Yorkshire's existing combination of physical and virtual servers with a more efficient and scalable virtual solution. Key technologies used included VMware vSphere, VMware ESXi, vCenter Server, VMware Workstation, VMware Converter, Windows Server 2019, Windows 10, Windows Server 2022, Active Directory, and an iSCSI SAN LUN formatted as a VMFS datastore.

The lab was executed in two main phases. Phase I focused on setting up the environment, which involved installing and configuring two ESXi servers, deploying the vCenter Server Virtual Appliance, and migrating existing virtual machines (VMs) from a VMware Workstation environment into the new ESXi environment. Phase II concentrated on configuring the SAN datastore and managing virtual machines, including tasks like integrating Active Directory, configuring network adapters, and setting up a VMFS datastore on the SAN.

Several significant accomplishments were achieved during this project. Two ESXi servers were successfully installed and configured with appropriate hardware settings. The vCenter Server was deployed and integrated into the Active Directory domain, facilitating better management and security. The Windows 11 VM was successfully migrated from VMware Workstation to the ESXi server. Additionally, the physical-to-virtual (P-to-V) conversion of the domain controller was completed using VMware Converter. The SAN datastore was configured to be accessed by both ESXi servers, providing a shared storage solution. A new Windows Server 2019 VM was installed and saved as a template for future use. VMware snapshots and vMotion were utilized to manage and migrate VMs effectively.

Despite these successes, the project encountered some challenges. One major issue was the initial failure to join the vCenter Server to the Active Directory domain due to DNS resolution problems. This was resolved by manually specifying the domain controller's IP address during the domain join process. Another issue was the failure of the P-to-V conversion due to insufficient disk space on the target ESXi server, which was resolved by correctly configuring the thin provisioned disk size.

In conclusion, the project successfully achieved its goals of fully virtualizing and optimizing Yorkshire's IT infrastructure. The recommendations for future improvements include regularly taking snapshots before making significant changes, ensuring proper disk provisioning settings, verifying DNS and network settings before joining domains, and regularly rescanning storage adapters when configuring shared storage.

The appendices of this report contain detailed problem-solving documentation for the issues encountered, including the steps taken to resolve them, ensuring a comprehensive understanding of the project's challenges and solutions.
* Business Case
Yorkshire is a small but rapidly expanding school system driven by rising suburbanization and increasing demand for its IT services. To meet these growing demands, Yorkshire embarked on a project to enhance its IT infrastructure by transitioning to a fully virtualized environment. This project aimed to optimize resource utilization, improve scalability, and strengthen disaster recovery capabilities. The primary objective was to replace Yorkshire's current combination of physical and virtual servers with a more efficient and scalable solution using VMware vSphere. The specific goals included improving the utilization of IT resources to handle the increasing workload efficiently, ensuring the infrastructure could easily scale to accommodate future growth, and enhancing disaster recovery capabilities to minimize downtime and data loss in case of hardware failures or other disruptions.The applications and technologies used in this project included VMware vSphere, VMware ESXi, vCenter Server, VMware Workstation, VMware Converter, Windows Server 2019, Windows 10, Windows Server 2022, Active Directory, and an iSCSI SAN LUN formatted as a VMFS datastore. By transitioning to a fully virtualized environment, Yorkshire aimed to provide a more reliable, scalable, and efficient IT infrastructure, better suited to support its growing needs and future expansion plans.
* Procedures

In this lab, we followed a two-phase process to convert a virtual environment into a nested virtual environment using VMware vSphere. Each phase had distinct objectives and steps, which were organized based on tasks and components involved. This documentation is written in past tense to accurately describe the procedures followed. The formatting is as follows: buttons are *bold*, options are _italicized_, text entered into the computer is in `code`, and menu navigation is indicated by the pipe symbol and italic words: _Start | Programs | MS Office | Word_.

** Phase I: Setting Up the Environment
*** 1. Install ESXi Servers:
   - Configured hardware settings: set CPU, hard disk, memory, and port group.
     - _CPU_: 8 CPUs
     - _Memory_: 32 GB RAM
     - _Hard Disk_: 1 TB Thin Provisioned Disk
     - _Enable hardware virtualization_: Check *Expose hardware-assisted virtualization to the guest OS* under the _CPU_ tab.
   - Launched the ESXi server installer:
     - Inserted the ESXi installer ISO and booted the server.
     - Accepted the default options to complete the installation.
   - Connected to the ESXi server via a Windows 10 machine:
     - Opened a browser and navigated to the ESXi server's IP address.
     - Logged in with the credentials created during installation.

*** 2. Install vCenter Server Virtual Appliance:
   - Accessed the RTFM fileshare and opened the installer:
     - Navigated to the folder containing the installer: _win32 installer_.
     - Launched the installer.
   - Followed the installation steps:
     - Entered the ESXi IPv4 settings, username, and password.
     - Set up the root password and name.
     - Configured the deployment size (left as default).
     - Enabled thin disk mode.
     - Assigned an IP address, set the default gateway and network mask.
     - Entered the DNS server IP from the Windows server.
     - Verified settings and clicked *Finish*.
     - Waited for the installation to complete.

*** 3. Configuration and Deployment:
   - Completed Phase I and proceeded to Phase II by clicking *Next*.
   - Added the ESXi host:
     - Opened vCenter and logged in with `administrator@vsphere.local`.
     - Navigated to _Hosts and Clusters_.
     - Clicked *Add Host*.
     - Entered the ESXi host IP address, username, and password.
     - Accepted the default options to complete the addition of the host.
   - Activated SSH:
     - Selected the ESXi host and navigated to _Configure | Services_.
     - Located *SSH*, clicked *Edit*, and set it to *Start and stop with host*.
   - Created a new Single Sign-On (SSO) domain:
     - During vCenter setup, created an SSO domain named `vsphere.local`.
     - Set up the SSO password, clicked *Next*, and finished the setup.
     - Closed the setup wizard.

*** 4. vSphere Setup:
   - Logged into vSphere using `administrator@vsphere.local`.
   - Created a new datacenter:
     - Navigated to _Hosts and Clusters_.
     - Right-clicked on the vCenter server and selected *New Datacenter*.
     - Named the datacenter and clicked *OK*.
   - Added ESXi hosts:
     - Right-clicked the newly created datacenter and selected *Add Host*.
     - Entered the IP address, username, and password of the ESXi host.
     - Accepted the default prompts to add the host to the datacenter.
   - Configured the ESXi management network:
     - Pressed `F2` on the ESXi host console to customize the system.
     - Navigated to _Configure Management Network | IPv4 Configuration_.
     - Set static IPv4 address, subnet mask, and default gateway.
     - Navigated to _DNS Configuration_ and set the DNS server to the Windows server IP.
     - Restarted the management network.

*** 5. Active Directory Integration:
   - Configured NTP, hostname, DNS, and gateway for vCenter:
     - Logged into vSphere.
     - Navigated to _Administration | System Configuration_.
     - Selected the vCenter server and clicked *Configure*.
     - Set NTP settings, hostname, DNS, and gateway.
   - Joined Active Directory Domain:
     - Navigated to _Administration | Active Directory Domain_.
     - Clicked *Join Domain*, entered the domain details, and rebooted the node.
   - Configured forward zone for vCenter in the DNS server.

*** 6. Moving Windows 11 Virtual Machine:
   - Used VMware Converter to move the VM from Windows 11 Workstation to ESXi server:
     - Opened VMware Converter.
     - Selected *Convert Machine*.
     - Chose the option for VMware Workstation or other VMware virtual machine.
     - Browsed and selected the virtual machine file.
     - Entered vCenter IP and SSO information.
     - Verified settings and clicked *Finish*.

*** 7. Physical to Virtual (P-to-V) Conversion:
   - Installed VMware Converter on the domain controller:
     - Downloaded and installed VMware Converter.
     - Launched the Converter and selected the domain controller as the source.
     - Set the destination as vCenter using its IP and SSO credentials.
     - Chose thin provisioning and accepted defaults.
     - Shut down the original server.
     - Powered on the new virtual server in vCenter.
     - Reconfigured IPv4 settings to the previous settings for the domain controller.
** Phase II: Configuring SAN Datastore and Managing Virtual Machines
*** 1. Configure SAN Datastore:
   - Logged into vCenter.
   - Clicked on the ESXi host, navigated to _Configure | Storage Adapters_.
   - Added a new iSCSI adapter:
     - Clicked *Add Software Adapter*.
     - Selected the iSCSI adapter created.
     - Went to _Dynamic Discovery_ and added the SAN IP address.

*** 2. Network Adapter Configuration:
   - Opened vCenter, selected the ESXi server.
   - Under VM Hardware, added a new network adapter:
     - Clicked *Edit* under the VM Hardware section.
     - Selected *Add New Device* and chose *Network Adapter*.
     - Configured the new network adapter to use the CNIT242 iSCSI port group.
     - Clicked *OK*.

*** 3. Storage Configuration:
   - Repeated the above steps for the second ESXi host.
   - Created a new VMFS datastore:
     - Clicked *Storage*.
     - Selected *New Datastore*.
     - Chose *VMFS* and selected the FreeNAS iSCSI disk.
     - Used the full disk and selected VMFS 6.
   - Added VM Kernel NIC:
     - Navigated to _Networking_.
     - Clicked *Add VMkernel NIC*.
     - Created a new port group named CNIT242 iSCSI.
     - Selected the appropriate vSwitch and set IPv4 to static.
     - Entered IP address `192.168.52.10` and subnet mask `255.255.255.0`.
     - Clicked *Create*.

*** 4. Enable iSCSI Adapter:
   - Navigated to _Storage_.
   - Selected the iSCSI adapter and ensured it was enabled.
   - Added dynamic targets:
     - Clicked *Port Bindings* and selected the VMkernel interface created.
     - Added a dynamic target with IP address `192.168.52.254` and port `3260`.

*** 5. Installed Windows Server 2019 Virtual Machine:
   - Inside vCenter, navigated to the target datastore (e.g., datastore1).
   - Clicked *Upload Files*.
   - Accessed the network location `\\rtfm.cit.lcl`.
   - Located and selected the Windows Server 2019 ISO file.
   - Selected an ESXi host (e.g., 44.100.10.191).
   - Created a new virtual machine:
     - Named it WindowsServer2019.
     - Selected datastore and compute resource (ESXi host address).
     - Chose storage (same datastore as before).
     - Compatibility set to ESXi 8 and later.
     - Accepted defaults for guest OS.
     - Modified disk provisioning to *Thin*.
     - Added CD/DVD drive, connected ISO file (`datastore1` → Windows Server 2019 ISO).
     - Finished setup.
   - Powered on Windows Server 2019 VM.
   - Proceeded with installation, created admin account.
   - Installed VMware Tools, mounted and ran setup.
   - Configured network settings (Ethernet0):
     - Set IP address to 44.100.10.11, subnet mask to 255.255.255.0, default gateway to 44.100.10.1, DNS to 44.100.10.10.
   - Restarted Windows Server 2019.
   - Checked for updates, installed, and restarted.
   - Configured NTP time server:
     - Opened Command Prompt as admin.
     - Configured time server: `w32tm /config /manualpeerlist:"tick.cit.lcl" /syncfromflags:manual /reliable:YES /update`.
     - Resynchronized time: `w32tm /resync`.
     - Verified changes: `w32tm /query /status`.
   - Powered off Windows Server 2019.
   - Converted VM to template: Right-clicked → *Template* → *Convert to template*.
   - Moved template to SAN datastore:
     - Navigated to ESXi host interface holding Windows Server 2019.
     - Went to *Storage* → *Datastore Browser*.
     - Located template on `datastore1`, moved it to `SANdatastoreG10`.
   - Registered template as VM in vCenter:
     - Navigated to the folder where Windows Server 2019 template was moved (SANdatastoreG10).
     - Found `.vmtx` file, clicked to select.
     - Clicked *Register VM*.
     - Named VM, selected datastore, compute resource, and finished.

*** 6. Set Permissions:
   - Inside vCenter, navigated to Windows 11 VM.
   - Went to *Permissions* tab.
   - Clicked *Add*.
   - Changed domain to Active Directory domain (`group10.c242.cit.lcl`).
   - Added user (e.g., ESstudents).
   - Assigned role (e.g., Read only).
   - Clicked *OK*.

*** 7. Migrated Storage to SAN (Storage vMotion):
   - Inside vCenter, found Windows 11 VM in the sidebar.
   - Right-clicked and selected *Migrate*.
   - Chose *Change storage only*.
   - Clicked *Next*.
   - In *Select Storage*, chose:
     - Virtual disk format: *Thin Provision*.
     - Destination datastore: `SANdatastoreG10`.
   - Clicked *Next* and *Finish*.
   - Monitored progress in *Monitor → Tasks and Events → Tasks*.
   - VM could still be used during migration.

*** 8. Migrated Compute Resource (vMotion):
   - Inside vCenter, found Windows 11 VM in the sidebar.
   - Right-clicked and selected *Migrate*.
   - Chose *Change compute resource only*.
   - Clicked *Next*.
   - Selected the target ESXi host (e.g., `44.100.10.192`).
   - Accepted default options.
   - Clicked *Finish*.
   - VM remained operational during migration.
\newpage
* Results
In this lab, a nested virtual environment was successfully created and configured using VMware vSphere. This involved setting up two ESXi servers, installing a vCenter server, and migrating existing virtual machines from a VMware Workstation environment into the new ESXi environment. Various VMware tools and techniques were utilized to manage and optimize the virtual environment, ensuring efficient resource allocation and network configuration. The following sections detail the physical and logical network setups, the IP schema, and computer names along with login information.
** Summary of Accomplishments
- Installation and Configuration of ESXi Servers
   + Two ESXi servers were successfully installed and configured with 8 CPUs, 32 GB RAM, and 1 TB thin provisioned disks. Hardware virtualization was enabled.
#+ATTR_ORG: :width 800 :align center
#+ATTR_LATEX: :width 14cm :align left :placement [H]
#+CAPTION: Outer vCenter virtualization environment. Specifically showing information on ESXi1.2
[[/home/sam/Screenshots/screenshot_2024-06-20_16-18-56.png]]
#+ATTR_ORG: :width 800 :align center
#+ATTR_LATEX: :width 14cm :align left :placement [H]
#+CAPTION: Inside ESXi2.1's web interface. Shows the VMkernal NIC's inside the networking tab.
[[/home/sam/Screenshots/screenshot_2024-06-20_16-25-20.png]]
- Deployment of vCenter Server
   + vCenter Server was installed, configured, and joined to the Active Directory domain.
#+ATTR_ORG: :width 800 :align center
#+ATTR_LATEX: :width 14cm :align left :placement [H]
#+CAPTION: Inner Vcenter virtualization environment. Specifically showing information on SCDC01.
[[/home/sam/Screenshots/screenshot_2024-06-20_16-21-27.png]]
- Migration of Windows 11 VM
   + The Windows 11 VM was successfully migrated from VMware Workstation to the ESXi server and added to the inventory.
#+ATTR_ORG: :width 800 :align center
#+ATTR_LATEX: :width 14cm :align left :placement [H]
#+CAPTION: Inner vCenter virtualization environment. Shows the permissions for the windows 11 VM.
[[/home/sam/Screenshots/screenshot_2024-06-20_16-26-27.png]]
- P-to-V Conversion of Domain Controller
   + Using VMware Converter, the domain controller was migrated from a physical to a virtual environment on the ESXi server.
- Configuration of SAN Datastore
#+ATTR_ORG: :width 800 :align center
#+ATTR_LATEX: :width 14cm :align left :placement [H]
#+CAPTION: Inside ESXi2.1's web interface. Showing the datastores datastore1(1) and SANdatastoreG10.
[[/home/sam/Screenshots/screenshot_2024-06-20_16-23-08.png]]
   + Both ESXi servers were configured to access an iSCSI SAN LUN and formatted as a VMFS datastore.
- Installation and Template Creation of Windows Server 2019
   + A fresh Windows Server 2019 was installed, updated, and saved as a template for future use.
- Virtual Machine Management
   + VMware Snapshots were used to protect configurations during changes, and virtual machine access was controlled through vCenter permissions.
- Virtual Machine Migration
   + VMs were migrated between datastores and ESXi hosts using vMotion and storage vMotion.
\newgeometry{left=1cm,right=1cm,top=4cm,bottom=1cm}
** Machine Networking/Login Information Table
\centering
|------------------------+-----------------------------+---------------------+-----------------|
| table                  |            *ESXi1.2 Server* |    *ESXi2.1 Server* | *vCenter*       |
|------------------------+-----------------------------+---------------------+-----------------|
| *Pnic1 (CNIT242G10A)*  |               44.100.10.191 |       44.100.10.192 | 44.100.10.170   |
| *Pnic2 (CNIT242iSCSI)* |               192.168.52.10 |       192.168.54.10 | N/A             |
| *Subnet Mask*          |               255.255.255.0 |       255.255.255.0 | 255.255.255.0   |
| *Default Gateway*      |                 44.100.10.1 |         44.100.10.1 | 44.100.10.1     |
| *DNS*                  |                44.100.10.10 |        44.100.10.10 | 44.100.10.10    |
| *SAN server IP*        |              192.168.52.254 |      192.168.54.254 | N/A             |
| *Login*                |                        root |                root | administrator   |
| *Password*             |                    Cnit242! |            Cnit242! | Cnit242!        |
|------------------------+-----------------------------+---------------------+-----------------|
|------------------------+-----------------------------+---------------------+-----------------|
|                        |                             |                     |                 |
| table cont.            | *Windows 2022 Srv.(SCDC01)* | *Windows 2019 Srv.* | *Windows 11 VM* |
|------------------------+-----------------------------+---------------------+-----------------|
| *Pnic1 (CNIT242G10A)*  |                44.100.10.10 |        44.100.10.11 | 44.100.10.111   |
| *Pnic2 (CNIT242iSCSI)* |                         N/A |                 N/A | N/A             |
| *Subnet Mask*          |               255.255.255.0 |       255.255.255.0 | 255.255.255.0   |
| *Default Gateway*      |                 44.100.10.1 |         44.100.10.1 | 44.100.10.1     |
| *DNS*                  |                44.100.10.10 |        44.100.10.10 | 44.100.10.10    |
| *SAN server IP*        |                         N/A |                 N/A | N/A             |
| *Login*                |               Administrator |       Administrator | Administrator   |
| *Password*             |                    Cnit242! |            Cnit242! | Cnit242!        |
|------------------------+-----------------------------+---------------------+-----------------|
\restoregeometry
** Diagrams
#+ATTR_ORG: :width 800 :align center
#+ATTR_LATEX: :width 15cm :align left :placement [H]
#+CAPTION: Physical topology diagram.
[[/home/sam/Screenshots/screenshot_2024-06-22_21-54-02.png]]
#+ATTR_ORG: :width 800 :align center
#+ATTR_LATEX: :width 15cm :align left :placement [H]
#+CAPTION: Logical topology diagram.
[[/home/sam/Screenshots/screenshot_2024-06-22_21-56-42.png]]
* Conclusions
In the final analysis of the project, it can be concluded that it was a success in achieving the goal of fully virtualizing and optimizing the infrastructure at Yorkshire's school system. The primary objectives included installing and integrating two ESXi servers and configuring a SAN datastore, both of which were met effectively.

Firstly, the ESXi servers were successfully installed and configured. Using vCenter, these servers were joined to the pre-existing Active Directory domain, enabling administrators to assign VMs to users based on their group memberships. This integration was crucial for maintaining a seamless and secure IT environment.

Next, the migration of existing virtual machines was completed as planned. VMware Workstation facilitated the transfer of a Windows 11 VM to the ESXi server, while VMware Converter was utilized to perform a P-to-V conversion of the Windows Server 2022 domain controller, ensuring a smooth transition to the virtual environment.

The SAN datastore was then configured to access an iSCSI SAN LUN, formatted as a VMFS datastore. A new Windows Server 2019 VM was installed and saved as a template for future use. Subsequently, the Windows 11 VM was migrated from its local datastore on the ESXi server to the SAN datastore using storage vMotion. This configuration allowed administrators to move VMs freely between the two ESXi servers, enhancing resource flexibility and disaster recovery capabilities.

A snapshot was created to ensure there was a saved instance of the completed project, providing a reliable fallback option if needed. By successfully completing the objectives of installing and integrating ESXi servers, configuring the SAN datastore, and migrating VMs, the project achieved its overall goal of fully virtualizing and optimizing the school system’s infrastructure. Thus, the project can be deemed a success, meeting all requirements and expectations outlined in the business case.
* Recommendations
** Recommendation 1: Take Regular Snapshots
Regularly take snapshots of your VMs, especially before making significant changes or updates. This allows you to quickly revert to a known good state if something goes wrong, saving time and effort in troubleshooting and recovery.

** Recommendation 2: Ensure Proper Disk Provisioning
When setting up the ESXi servers, double-check the disk provisioning settings to confirm that the thin provisioned disks are correctly configured to the intended size. Misconfigurations in disk size can lead to insufficient disk space issues, which can disrupt tasks such as P-to-V conversions.

** Recommendation 3: Verify DNS and Network Settings Before Joining Domains
Before attempting to join the vCenter Server to the Active Directory domain, thoroughly verify DNS and network settings. Correct DNS configuration and network connectivity are crucial for successful domain integration. Manually specifying the domain controller's IP address can also help bypass potential DNS resolution issues.

** Recommendation 4: Regularly Rescan Storage Adapters When Configuring SAN
When configuring shared storage on ESXi servers, regularly rescan storage adapters to detect new devices and LUNs. This practice helps ensure that all storage resources are properly recognized and available for use. Additionally, verify iSCSI target configurations and LUN masking settings to avoid detection issues.

* Bibliography
Microsoft. (2022, August 16). Active Directory Domain Services Overview. Learn.microsoft.com. https://learn.microsoft.com/en-us/windows-server/identity/ad-ds/get-started/virtual-dc/active-directory-domain-services-overview

Microsoft. (2024a). Windows 11 overview for administrators - What’s new in Windows. Learn.microsoft.com.
https://learn.microsoft.com/en-us/windows/whats-new/windows-11-overview

Microsoft. (2024b). Windows Server Management documentation. Learn.microsoft.com.
https://learn.microsoft.com/en-us/windows-server/administration/manage-windows-server

VMware. (2019). VMware vSphere Documentation. Vmware.com.\\
https://docs.vmware.com/en/VMware-vSphere/index.html

Rawles, P. (2024). Lab Instructor. Instruction Video.\\
https://purdue.brightspace.com \\

Wong, O. (2024). Lab TA. Personal communication.\\
https://discord.com

Akpeokhai, O. (2024). Lab TA. Personal communication. \\
https://discord.com

* APPENDIX: PROBLEM SOLVING

This section describes several issues faced throughout this project. Each problem is broken down by giving a Problem Description; listing Possible Solutions, accompanied by the reasoning for it; Solutions Attempted, which simply list which options from the Possible Solutions list that were attempted; and finally, a detailed description of the Final Solution and why it solved the problem.

** Problem 1: vCenter Server Fails to Join Active Directory Domain
*** Problem Description
While attempting to join the vCenter Server Virtual Appliance to the Active Directory domain, the operation fails with an error indicating that the domain cannot be found. This issue occurs despite verifying that the network settings and DNS configurations appear correct. This problem prevents the vCenter Server from integrating with the AD domain, which is necessary for managing permissions and integrating with existing infrastructure.

*** Possible Solutions
- Check DNS Configuration: Ensure that the DNS server settings on the vCenter Server are correctly pointing to the domain controller's IP address. Incorrect DNS settings can prevent domain resolution.
- Verify Network Connectivity: Test the network connectivity between the vCenter Server and the domain controller to ensure there are no network issues blocking the communication.
- Update vCenter Server: Apply the latest updates and patches to the vCenter Server Virtual Appliance, as there may be known bugs or issues that have been fixed.
- Manually Add Domain Controller: Manually specify the domain controller's IP address during the domain join process to bypass potential DNS resolution issues.
- Check AD Credentials: Ensure that the credentials used for joining the domain have sufficient permissions and that there are no account restrictions.

*** Solutions Attempted
- Checked DNS Configuration.
- Verified Network Connectivity.
- Updated vCenter Server.

*** Final Solution
The problem was resolved by manually specifying the domain controller's IP address during the domain join process. This bypassed the DNS resolution issue, allowing the vCenter Server to successfully join the Active Directory domain. Additionally, ensuring that the AD credentials used had sufficient permissions helped complete the operation without errors.

** Problem 2: P-to-V Conversion Fails Due to Insufficient Disk Space
*** Problem Description
While performing a physical-to-virtual (P-to-V) conversion of the existing domain controller using VMware Converter, the process fails with an error indicating insufficient disk space on the target ESXi server. This issue occurs despite the intention to provision a 1 TB thin provisioned disk on the ESXi server. Upon further inspection, it was found that the disk size was improperly set up, and the actual allocated space was significantly less than 1 TB.

*** Possible Solutions
- Check Disk Space Allocation: Verify the actual disk usage on the ESXi server and ensure that there is enough physical storage available for the conversion process.
- Increase Thin Provisioned Disk Size: Correct the thin provisioned disk size on the ESXi server to ensure it is properly set to 1 TB.
- Clear Unnecessary Files: Remove unnecessary files and unused VMs from the ESXi server to free up disk space.
- Use External Storage: Use an external storage device or an additional datastore to provide more disk space for the conversion.
- Compress Source Disk: Compress the source disk of the physical machine before performing the conversion to reduce the amount of disk space needed.

*** Solutions Attempted
- Checked Disk Space Allocation.
- Increased Thin Provisioned Disk Size.

*** Final Solution
The problem was resolved by correcting the thin provisioned disk size on the ESXi server. It was discovered that the disk size was improperly configured, and the actual allocated space was much less than the intended 1 TB. By properly setting the thin provisioned disk to 1 TB, the ESXi server then had sufficient disk space for the P-to-V conversion process. After this adjustment, the conversion of the domain controller completed successfully. This solution was effective because it directly addressed the root cause of the disk space insufficiency without the need for additional hardware or extensive cleanup efforts.

** Problem 3: iSCSI SAN LUN Not Detected by ESXi Servers
*** Problem Description
While attempting to configure both VMware ESXi servers to access an iSCSI SAN LUN and format it as a VMFS datastore, the LUN is not detected by the ESXi servers. This issue occurs despite confirming that the network settings for the iSCSI initiator and target are correct. The failure to detect the LUN prevents the configuration of shared storage necessary for advanced features like vMotion and high availability.

*** Possible Solutions
- Verify iSCSI Target Configuration: Ensure that the iSCSI target is correctly configured to accept connections from the ESXi servers' IP addresses.
- Check Network Connectivity: Confirm that there is proper network connectivity between the ESXi servers and the iSCSI SAN, including verifying that firewalls are not blocking iSCSI traffic.
- Rescan Storage Adapters: Use the vSphere Client to rescan the storage adapters on the ESXi servers to detect new devices and LUNs.
- Update ESXi Servers: Apply the latest updates and patches to the ESXi servers to address any known issues with iSCSI connectivity.
- Verify iSCSI Initiator Configuration: Ensure that the iSCSI initiator on each ESXi server is correctly configured with the appropriate settings, such as the target portal IP address.

*** Solutions Attempted
- Verified iSCSI Target Configuration.
- Checked Network Connectivity.
- Rescanned Storage Adapters.

*** Final Solution
The problem was resolved by adjusting the iSCSI target configuration on the SAN. It was discovered that the LUN masking settings on the iSCSI SAN were incorrectly configured, preventing the LUN from being visible to the ESXi servers. By correcting the LUN masking settings to explicitly allow access from the ESXi servers' initiator IQNs, the LUN was successfully detected. A rescan of the storage adapters in the vSphere Client then revealed the LUN, which was subsequently formatted as a VMFS datastore. This allowed the ESXi servers to access the shared storage as intended.
